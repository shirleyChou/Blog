<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Zhou Yi</title>
    <link>http://shirleychou.github.io/blog/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Zhou Yi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2016. All rights reserved.</copyright>
    <lastBuildDate>Thu, 10 Mar 2016 11:23:42 +0800</lastBuildDate>
    <atom:link href="http://shirleychou.github.io/blog/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Regularization</title>
      <link>http://shirleychou.github.io/blog/2016/03/10/regularization/</link>
      <pubDate>Thu, 10 Mar 2016 11:23:42 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/03/10/regularization/</guid>
      <description>

&lt;h4 id=&#34;the-problem-of-overfitting:b78a93f3befe9e730fab504843530378&#34;&gt;The problem of overfitting&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Underfitting&lt;/strong&gt;: also called &amp;ldquo;High bias(preconception)&amp;rdquo;, which mean that it&amp;rsquo;s not even fitting the training data very well.&lt;/p&gt;

&lt;p&gt;Example of linear regression:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/underfit.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Example of logistic regression:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/underfit-logistic.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Overfitting&lt;/strong&gt;: If we have too many features, the learned hypothesis may fit the training set very well (J(θ) ≈ 0), but fail to generalize(how well a hypothesis applies even to new example) to new examples (predict prices on new examples).&lt;/p&gt;

&lt;p&gt;Example of linear regression:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/overfit.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Example of logistic regression:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/overfit-logistic.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;addressing-overfitting:b78a93f3befe9e730fab504843530378&#34;&gt;Addressing overfitting&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Plotting the hypothesis&lt;/strong&gt; can be one way to decide what degree polynomial to use. But it cannot often work, because often we have learning problems that where we just have a lot of features and it would be much harder to visualize the data.&lt;/p&gt;

&lt;h5 id=&#34;so-some-options-are:b78a93f3befe9e730fab504843530378&#34;&gt;So some options are:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reduce number of features&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Manually select which features to keep(it may throw away some informations your have about the problem).&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Model selection algorithm (later in course).&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Regularization&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Keep all the features, but reduce magnitude/values of parameters θj.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Works well when we have &lt;strong&gt;a lot of features&lt;/strong&gt;, each of which contributes a bit to predicting &lt;em&gt;y&lt;/em&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;regularization:b78a93f3befe9e730fab504843530378&#34;&gt;Regularization&lt;/h3&gt;

&lt;p&gt;Regularization is a way to address overfitting by making the value of parameters theta really small. so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/intuition.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;What regularization does it to add a regularization term to the cost function J of theta, and &lt;strong&gt;λ&lt;/strong&gt; is called &lt;strong&gt;regularization parameter&lt;/strong&gt;. And what λ does it controls a trade off between two different goals. The goal of the regularization term is to keep the parameters small, and thus keep the hypothesis relatively simple to avoid overfitting. The first term of the cost function is to fit the training set well.&lt;/p&gt;

&lt;h5 id=&#34;but-what-if-λ-is-set-to-an-extremely-large-value-perhaps-for-too-large-for-our-problem-say-λ-10-10:b78a93f3befe9e730fab504843530378&#34;&gt;But What if λ is set to an extremely large value (perhaps for too large for our problem, say λ = 10^(10))?&lt;/h5&gt;

&lt;p&gt;Then θ1, θ2, θ3, θ4&amp;hellip; ≈ 0, hypothesis h may be underfitting (become horizontal flat line). For regularization to work well. some care should be taken, to choose a good choice for the regularization parameter λ as well.&lt;/p&gt;

&lt;h3 id=&#34;regularized-linear-regression:b78a93f3befe9e730fab504843530378&#34;&gt;Regularized linear regression&lt;/h3&gt;

&lt;p&gt;The goal is to minimize J of theta, &lt;strong&gt;be aware of that j is starting from 1!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/regularization.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; for regularized logistic regression is:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/theta0.JPG?raw=true&#34; alt=&#34;&#34; /&gt;

&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/thetaj.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The first term (1 - α * λ / m) &amp;lt; 1, so theta J times a term which is less than one has the effect of shrinking theta J a little bit towards 0. So this makes theta J a bit smaller.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Normal equation&lt;/strong&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/normal.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Suppose m (#examples) ≤ n (#features)&lt;/strong&gt;, i.e. you have lots of features in a relatively small training set, θ would be non-invertible/singular&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/theta.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;But if λ &amp;gt; 0, θ with &lt;strong&gt;regularization term is invertible&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/theta-invertible.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h3 id=&#34;regularized-logistic-regression:b78a93f3befe9e730fab504843530378&#34;&gt;Regularized logistic regression&lt;/h3&gt;

&lt;p&gt;The cost function and the gradient descent(or maybe using Advanced optimization) is the same as Regularized linear regression except the hypothesis is &lt;strong&gt;Sigmoid function&lt;/strong&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>http://shirleychou.github.io/blog/2016/03/08/logistic-regression/</link>
      <pubDate>Tue, 08 Mar 2016 17:54:57 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/03/08/logistic-regression/</guid>
      <description>

&lt;h3 id=&#34;logistic-regression-model:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Logistic Regression Model&lt;/h3&gt;

&lt;p&gt;Logistic regression is a classification algorithm. It generates a value where is between 0 and 1.&lt;/p&gt;

&lt;p&gt;And the hypothesis(function) of logistic regression is:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/function.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;i.e.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/hypothesis.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The hypothesis is alse called &amp;ldquo;&lt;strong&gt;Sigmoid function&lt;/strong&gt;&amp;rdquo;, or &amp;ldquo;&lt;strong&gt;Logistic function&lt;/strong&gt;&amp;rdquo;. The term &lt;code&gt;Logistic function&lt;/code&gt; is what give rise to the name logistic progression. The term &lt;code&gt;Sigmoid function&lt;/code&gt; and the term &lt;code&gt;Logistic function&lt;/code&gt; are basically synonyms and mean the same thing. So either term can be used to refer to the function g.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Sigmoid function&lt;/strong&gt; looks like:&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/graph.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;so-when-make-predictions-that-y-1-or-0:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;So, when make predictions that y = 1(or 0)?&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;when g(z) ≥ 0.5, z ≥ 0, predict &amp;ldquo;y = 1&amp;rdquo;&lt;/li&gt;
&lt;li&gt;when g(z) ≤ 0.5, z ≤ 0, predict &amp;ldquo;y = 0&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;interpretation-of-hypothesis-output:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Interpretation of Hypothesis Output&lt;/h4&gt;

&lt;p&gt;When hypothesis outputs some number, we going to treat that number as the estimated probability that Y = 1 on a new input example X. Here is an example (y = 1 === malignant):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/example.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;To write in more formally, we say hypothesis h(x) is the probability that y = 1, given x,
parameterized by theta:
&amp;gt; h(x) = P(y = 1 | x; theta) = 0.7&lt;/p&gt;

&lt;p&gt;So, we also know that:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/probability.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The first equation is saying that the probability of Y equals zero for a particular patient with feature x, plus probability of Y equals one for that same patient must add up to one.&lt;/p&gt;

&lt;h3 id=&#34;decision-boundary:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Decision Boundary&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s say we decide the hypothesis is h(x) with θ0 = -3, θ1 = 1 and θ2 = 1. &lt;strong&gt;Decision boundary&lt;/strong&gt; is the line when z = θ.T.dot(X) = 0.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/decision-boundary.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Decision boundary can also be non-linear.It can look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/db1.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Or looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/db2.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The shape of the decision boundary is decided by z.&lt;/p&gt;

&lt;h3 id=&#34;cost-function:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Cost function&lt;/h3&gt;

&lt;p&gt;We cannot use the cost function of linear regression for logistic regression, since the cost function of linear regression with hypothesis of logistic regression would be a &lt;strong&gt;non-convex&lt;/strong&gt; function of the parameters theta. So it &lt;strong&gt;not guarantee to converge to the global minimum&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Cost function of linear regression below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/linear-cost-function.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The meaning of non-convex&lt;/strong&gt; is that it could have many &lt;strong&gt;local optima&lt;/strong&gt;. And &lt;strong&gt;non-convex&lt;/strong&gt; is its formal term.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/not-convex.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The cost function that is &lt;strong&gt;&amp;ldquo;convex&amp;rdquo;&lt;/strong&gt; for the cost function is:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/cost-function-logistic.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;And we plot these two cost function respectively when y = 1 and y = 0.&lt;/p&gt;

&lt;p&gt;If y = 1:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/y=1.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;If y = 0:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/y=0.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h3 id=&#34;simplified-cost-function-and-gradient-descent:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Simplified cost function and gradient descent&lt;/h3&gt;

&lt;p&gt;So, combine y we can get the cost function of logistic regression as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/combine.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;And the goal is to minimize J of theta to get parameters θ, and then use those parameters to make a prediction given new x.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; for cost function of logistic regression is:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/grad.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm looks identical to linear regression!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Question: how to monitor gradient descent to make sure it&amp;rsquo;s conversion correctly.&lt;/p&gt;

&lt;h3 id=&#34;advanced-optimization-algorithms:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Advanced optimization algorithms&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Gradient descent&lt;/li&gt;
&lt;li&gt;Conjugate gradient&lt;/li&gt;
&lt;li&gt;BFGS&lt;/li&gt;
&lt;li&gt;L-BFGS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Either of these sophisticated optimization algorithms can be used to compute J of theta, and need a way to compute the derivatives, and than can use more sophisticated strategies than gradient descent to minimize the cost function. And Andrew Ng have used these algorithms like maybe over a decade.&lt;/p&gt;

&lt;p&gt;Other three algorithms have a number of &lt;strong&gt;pros and cons&lt;/strong&gt;.&lt;/p&gt;

&lt;h5 id=&#34;advantages:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Advantages&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;No need to manually pick alpha (automatically pick)&lt;/li&gt;
&lt;li&gt;Often &lt;strong&gt;faster&lt;/strong&gt; than gradient descent.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;disadvantages:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Disadvantages&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;More complex&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;multi-class-classification-one-vs-all:e3b7e24ffdafc5eafaa5482fd2cd2bf7&#34;&gt;Multi-class classification: One-vs-all&lt;/h3&gt;

&lt;p&gt;We can use logistic regression for binary classification problem:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/binary.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;But how about we have multi-class now?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/multi-class.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Use an idea called one versus all classification, we can take this and make it work for multi-class classification.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/one-vs-all.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The idea of One-vs-all is:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week3/idea.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine learning concepts</title>
      <link>http://shirleychou.github.io/blog/2016/02/23/machine-learning-concepts/</link>
      <pubDate>Tue, 23 Feb 2016 18:02:35 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/02/23/machine-learning-concepts/</guid>
      <description>

&lt;h2 id=&#34;introduction:89540e760d9dd0d7af01f229ce6a96f5&#34;&gt;Introduction&lt;/h2&gt;

&lt;h4 id=&#34;what-is-machine-learning:89540e760d9dd0d7af01f229ce6a96f5&#34;&gt;What is machine learning?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;DEFINITION&lt;/strong&gt;:&lt;br /&gt;
Tom Mitchell (1998) Well-posed Learning Problem: A computer program is said to learn from &lt;strong&gt;experience E&lt;/strong&gt; with respect to some &lt;strong&gt;task T&lt;/strong&gt; and some &lt;strong&gt;performance measure P&lt;/strong&gt;, if its performance on T, as measured by P, improves with experience E.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;EXAMPLE&lt;/strong&gt;:&lt;br /&gt;
Suppose your email program watches which emails you do or do not mark as spam, and based on that learns how to better filter spam. What is the task T in this setting?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Classifying emails as spam or not spam ( &lt;strong&gt;T&lt;/strong&gt; )&lt;/li&gt;
&lt;li&gt;Watching you label emails as spam or not spam ( &lt;strong&gt;E&lt;/strong&gt; )&lt;/li&gt;
&lt;li&gt;The number (or fraction) of emails correctly classified as spam/not spam ( &lt;strong&gt;P&lt;/strong&gt; )&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;several-types-of-machine-learning-algorithms:89540e760d9dd0d7af01f229ce6a96f5&#34;&gt;Several types of machine learning algorithms&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Supervised Learning&lt;/strong&gt;&lt;br /&gt;
Given the “right answer” for each example in the data.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Regression problem&lt;/strong&gt;&lt;br /&gt;
The target variable that we’re trying to predict is continuous&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Classification problem&lt;/strong&gt;&lt;br /&gt;
The target variable that we’re trying to predict is discrete&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unsupervised Learning&lt;/strong&gt;&lt;br /&gt;
Let the computer learn how to do something by thenselves.

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Clustering problem&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reinforcement learning&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semi-supervised Learning&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Linear Regression with multiable Variable</title>
      <link>http://shirleychou.github.io/blog/2016/01/26/linear-regression-with-multiable-variable/</link>
      <pubDate>Tue, 26 Jan 2016 17:25:34 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/01/26/linear-regression-with-multiable-variable/</guid>
      <description>

&lt;h3 id=&#34;multiple-features:18551688c5d64608a15d5425bef6ac07&#34;&gt;Multiple features&lt;/h3&gt;

&lt;p&gt;Multiple features equals to multiple variables.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/mul-variable.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;And definitely, the &lt;strong&gt;HYPOTHESIS&lt;/strong&gt; of linear regression would change:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/hypothesis.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;where theta are parameters.&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-for-multiple-variables:18551688c5d64608a15d5425bef6ac07&#34;&gt;Gradient descent for multiple variables&lt;/h3&gt;

&lt;p&gt;So as the number of parameter grows, remember to simultaneously update theta_j for j = 0,&amp;hellip;,n
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/grad.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;where &lt;strong&gt;COST FUNCTION&lt;/strong&gt; is still the same:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/cost.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-in-practice-i:18551688c5d64608a15d5425bef6ac07&#34;&gt;Gradient descent in practice I&lt;/h3&gt;

&lt;h4 id=&#34;feature-scaling:18551688c5d64608a15d5425bef6ac07&#34;&gt;Feature Scaling&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The idea of Feature Scaling is to make sure features are on a similar scale, then gradient descents can converge more quickly.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/feature-scaling.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;More generally, get every feature into approximately a -1 ≤ x ≤ 1 range.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/range.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;mean-normalization:18551688c5d64608a15d5425bef6ac07&#34;&gt;Mean normalization&lt;/h4&gt;

&lt;p&gt;In addition to dividing by so that the maximum value when performing feature scaling sometimes people will also do what&amp;rsquo;s call mean normalization, which means that replace x with x - μ to make features have approximately zero mean(Do not apply to x0 = 1)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/mean-normalization.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;parameters-explanation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Parameters explanation:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;μ1 - the average value of x in the training set&lt;/li&gt;
&lt;li&gt;s1 - the range(max - min) of values of that feature&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;gradient-descent-in-practice-ii:18551688c5d64608a15d5425bef6ac07&#34;&gt;Gradient descent in practice II&lt;/h3&gt;

&lt;h4 id=&#34;so-in-gradient-descent-how-do-we-make-sure-gradient-descent-is-working-correctly:18551688c5d64608a15d5425bef6ac07&#34;&gt;So in gradient descent, how do we make sure gradient descent is working correctly?&lt;/h4&gt;

&lt;p&gt;Here is something we can do. We know that the job of gradient descent is to find the theta for you that, you know, hopefully minimizes the cost function j of theta. So we pluck the cost function j of theta as the gradient descent runs. And plot that maybe looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/decrease.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So what this plot is showing, &lt;strong&gt;is it&amp;rsquo;s showing the value of your cost function after each iteration of gradient descent, and the gradient descent is working properly, then J of theta should decrease after every iteration&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In this case, we can tell gradient descent is not working
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/not-working.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;And one useful thing that this should of plot can tell you also is that by the time you&amp;rsquo;ve gotten out to maybe between three hundred and four hundred iterations, it looks like that J of theta hasn&amp;rsquo;t gone down much more. So it looks like that J of theta have more or less converged because your cost function isn&amp;rsquo;t going down much more. &lt;strong&gt;So looking at the figure can also help you judge whether or not gradient descent has converged&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;By the way, the number of iterations that gradient descent takes to converge for a particular application can vary a lot. &lt;strong&gt;So it is hard to tell how many iteration gradient descent needs to converge, and is usually by plotting this sort of plot to try to tell if gradient descent has converged&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;It is also possible to come up with &lt;strong&gt;automatic convergence test&lt;/strong&gt;, namely to have a algorithm to try to tell you if gradient descent has converged. Say we can declare convergence if J of theta decreases by less than 10^(-3) in one iteraion. But the threshold is very difficult to decide. So maybe simply plot the figure is a proper choice.&lt;/p&gt;

&lt;h4 id=&#34;how-to-choose-learning-rate-alpha:18551688c5d64608a15d5425bef6ac07&#34;&gt;How to choose learning rate alpha?&lt;/h4&gt;

&lt;p&gt;If alpha is too small, slow convergence. If alpha too large, J of theta may not decrease on every iteraion or may not converge.&lt;/p&gt;

&lt;p&gt;So when run gradient descent, try a range of values: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1 and pick the alpha seems to be causing J of theta to decrease rapidly.&lt;/p&gt;

&lt;h3 id=&#34;features-and-polynomial-regression:18551688c5d64608a15d5425bef6ac07&#34;&gt;Features and polynomial regression&lt;/h3&gt;

&lt;p&gt;How to get different algorithm, sometimes very powerful ones by choosing appropriate features.&lt;/p&gt;

&lt;p&gt;Suppose for housing prices prediction problem, we have two features: frontage, depth. But when we apply linear regression, you don&amp;rsquo;t necessary have to use the exactly features x1 and x2 but can create new features by yourself.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/area.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So sometimes by defining new features you might actually get a better model. Closing to the idea of choosing features is this idea called polynomial regression. Let&amp;rsquo;s say your house price looks like this:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/quad-and-cubic.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;We can apply quadratic function or cubic function, but both of these function may not be ideal. When we use cubic function, x1, x2 and x3 take a very diffierent ranges of values, and it&amp;rsquo;s important to use feature scaling if using gradient descent.&lt;/p&gt;

&lt;p&gt;So we may find another reasonable choice like this:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/ideal.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;We do have a broad choice on feature choosing for models.&lt;/p&gt;

&lt;h3 id=&#34;normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Normal equation&lt;/h3&gt;

&lt;p&gt;Normal equation, which for some linear regression problems, will give us a much better way to solve for the optimal value of the parameters theta.&lt;br /&gt;
&lt;strong&gt;Normal equation is a method to solve for theta analytically.i.e. we can instead just solve for the optimal value for theta all at one go&lt;/strong&gt;. So basically one step you get to the optimal value right there.&lt;/p&gt;

&lt;h4 id=&#34;formula-of-normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Formula of Normal equation&lt;/h4&gt;

&lt;p&gt;Using this formula &lt;strong&gt;does not require any feature scaling&lt;/strong&gt;, and you will get an exact solution in one calculation: there is no “loop until convergence” like in gradient descent.&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/normal-equation.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;intuition-of-normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Intuition of normal equation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/intuition.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;when-to-use-gradient-descent-and-when-to-use-normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;When to use gradient descent and when to use normal equation?&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/grad-and-NE.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So if n is large, use gradient descent to avoid to pay this all in q time, but if n is relatively small, then the normal equation might give you a better way to solve the parameters.&lt;/p&gt;

&lt;h5 id=&#34;what-does-the-small-and-large-means:18551688c5d64608a15d5425bef6ac07&#34;&gt;What does the small and large means?&lt;/h5&gt;

&lt;p&gt;If n is in the order of a thousand, still use  normal equation. But if n is ten thousand, inverting a ten-thousand by ten-thousand matrix starts to get kind of slow. And may then to lean in the direction of gradient descent. It is hard to give a strict number. It is usually around then thousand that start to consider switching over normal equation to gradient descent.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linear Regression with one variable</title>
      <link>http://shirleychou.github.io/blog/2016/01/25/linear-regression/</link>
      <pubDate>Mon, 25 Jan 2016 14:03:34 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/01/25/linear-regression/</guid>
      <description>

&lt;p&gt;Let’s start by talking about a few examples of supervised learning problems. Suppose we have a dataset giving the living areas and prices of 47 houses from Portland, Oregon:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/house-prices.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;To establish notation, use &lt;strong&gt;x(i)&lt;/strong&gt;(above) to denote the &amp;ldquo;input&amp;rdquo; variables (living area in this example), also called &lt;strong&gt;input features&lt;/strong&gt;, and &lt;strong&gt;y(i)&lt;/strong&gt; to denote the “output” or &lt;strong&gt;target variable&lt;/strong&gt; that we are trying to predict(price). A pair &lt;strong&gt;(x(i), y(i))&lt;/strong&gt; is called a &lt;strong&gt;training example&lt;/strong&gt;. And use &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; denote the space of input values, &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt; the space of output values. In this example, &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; = &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt; = &lt;strong&gt;&lt;em&gt;R&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;And the goal is, given a training set, to learn a function h : &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; → &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt; so that h(x) is a &amp;ldquo;good&amp;rdquo; predictor for the corresponding value of y. This function &lt;em&gt;h&lt;/em&gt; is called a &lt;strong&gt;hypothesis&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;To perform supervised learning, we must decide how we’re going to represent functions/hypotheses h in a computer. As an initial choice, let’s say we decide to approximate y as a linear function of x:&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/hypo.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;br /&gt;
Here, the θi’s are the &lt;strong&gt;parameters&lt;/strong&gt;(also called weights) parameterizing the space of linear functions mapping from &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;cost-function:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Cost function&lt;/h3&gt;

&lt;p&gt;Now, given a training set, how do we pick, or learn, the parameters θ? One reasonable method seems to be to make h(x) close to y, at least for the training examples we have. To formalize this, we will define a function that measures, for each value of the θ’s, how close the h(x(i))’s are to the corresponding y(i)’s. We define the cost function:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/cost.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;parameters-explanation:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Parameters explanation:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;This is called Squared error function&lt;/li&gt;
&lt;li&gt;1/2m

&lt;ul&gt;
&lt;li&gt;1/m - means we determine the average&lt;/li&gt;
&lt;li&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; - the 2 makes the math a bit easier, and doesn&amp;rsquo;t change the constants we determine at all (i.e. half the smallest value is still the smallest value!)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Minimizing θ0/θ1 means we get the values of θ0 and θ1 which find on average the minimal deviation of x from y when we use those parameters in our hypothesis function&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;cost-function-intuition:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Cost function intuition:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;Cost function is a way to, using your training data, determine values for your θ values which make the hypothesis as accurate as possible&lt;/li&gt;
&lt;li&gt;It also called the squared error cost function&lt;/li&gt;
&lt;li&gt;This cost function is reasonable choice for most regression functions. And is probably most commonly used function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;a-deeper-insight-into-the-cost-function:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;A deeper insight into the cost function&lt;/h3&gt;

&lt;p&gt;So we know that the cost function determines parameters. In order to visualize cost function J a little bit easier, we assume θ0 = 0 and now the goal is to minimize cost function J(θ1). If we compute a range of values plot, we get a polynomial (looks like a quadratic):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/theta_1.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The optimization objective for the learning algorithm is to find the value of θ1 which minimizes J(θ1). θ1 = 1 is the best value for θ1 here.&lt;/p&gt;

&lt;p&gt;Now we use our original complex hypothesis with two variables: J(θ0, θ1) and draw a &lt;strong&gt;3D surface plot&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/surface-plot.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;notice:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Notice&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;the height(y) indicates the value of the cost function, so the goal is to find where y is at a minimum.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And also, we can plot a &lt;strong&gt;contour plots&lt;/strong&gt; for better intuition:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/contour.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;notice-1:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Notice&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;each color is the same value of J(θ0, θ1), but obviously plot to different locations because θ1 and θ0 will vary&lt;/li&gt;
&lt;li&gt;each point (like the pink one above) represents a pair of parameter values for Ɵ0 and Ɵ1&lt;/li&gt;
&lt;li&gt;Finding Ɵ0 and Ɵ1 by eye/hand is in pain. What we really want is an efficient algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lms-algorithm:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;LMS algorithm&lt;/h2&gt;

&lt;p&gt;We want to choose θ so as to minimize J(θ). Specifically, let’s consider the &lt;strong&gt;gradient descent algorithm&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-algorithm:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Gradient descent algorithm&lt;/h3&gt;

&lt;h4 id=&#34;how-does-it-work:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;How does it work?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Start with initial guesses (0,0 (or any other value))&lt;/li&gt;
&lt;li&gt;Keeping changing θ0 and θ1 a little bit to try and reduce J(θ0, θ1). Each time you change the parameters, you select the gradient which reduces J(θ0,θ1) the most possible&lt;/li&gt;
&lt;li&gt;Repeat&lt;/li&gt;
&lt;li&gt;Do so until hopefully converge to a value of θ that minimizes J(θ)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;the-definition-of-gradient-descent-algorithm:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;The definition of gradient descent algorithm&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/grad.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;parameters-explanation-1:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Parameters explanation:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Alpha (learning rate)&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When you get to a local minimum, gradient of tangent/derivative is 0. So derivative term = 0 and theta remains the same.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/learning-rate.JPG?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;As we approach a local minimum, gradient descent will automatically take smaller steps. So no need to decrease alpha over time.&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/smallstep.JPG?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;derivative term&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Remember to use &lt;strong&gt;partial derivative&lt;/strong&gt; when we have multiple variables but only derive with respect to one.&lt;/li&gt;
&lt;li&gt;Despite the value of x (positive or negative), J(θ) will always reduce.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/derivative.JPG?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;notice-2:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Notice!&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;HAVE TO SIMULTANEOUSLY&lt;/strong&gt; update j = 0 and j = 1. If you implement the non-­simultaneous update it&amp;rsquo;s not gradient descent, and will behave weirdly.&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/theta_update.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;An interesting property: &lt;strong&gt;Where you start&lt;/strong&gt; can &lt;strong&gt;determine&lt;/strong&gt; which minimum you may end up
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/local-minimum.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;batch-gradient-descent:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;&amp;ldquo;Batch&amp;rdquo; Gradient Descent&lt;/h4&gt;

&lt;p&gt;“Batch”: Each step of gradient descent uses all the training examples.&lt;/p&gt;

&lt;h3 id=&#34;linear-regression-with-gradient-descent:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Linear regression with gradient descent&lt;/h3&gt;

&lt;p&gt;Apply gradient descent to minimize the squared error cost function J(θ0, θ1). When we derive this expression in terms of j = 0 and j = 1 we get the following:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/derive-cost.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Since the &lt;strong&gt;linear regression&lt;/strong&gt; cost function is always a convex function(Bowl shaped), So gradient descent will always converge to &lt;strong&gt;global optima&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>