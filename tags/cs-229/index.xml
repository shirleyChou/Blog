<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cs 229 on Zhou Yi</title>
    <link>http://shirleychou.github.io/blog/tags/cs-229/</link>
    <description>Recent content in Cs 229 on Zhou Yi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2016. All rights reserved.</copyright>
    <lastBuildDate>Tue, 26 Jan 2016 17:25:34 +0800</lastBuildDate>
    <atom:link href="http://shirleychou.github.io/blog/tags/cs-229/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Linear Regression with multiable Variable</title>
      <link>http://shirleychou.github.io/blog/2016/01/26/linear-regression-with-multiable-variable/</link>
      <pubDate>Tue, 26 Jan 2016 17:25:34 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/01/26/linear-regression-with-multiable-variable/</guid>
      <description>

&lt;h3 id=&#34;multiple-features:18551688c5d64608a15d5425bef6ac07&#34;&gt;Multiple features&lt;/h3&gt;

&lt;p&gt;Multiple features equals to multiple variables.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/mul-variable.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;And definitely, the &lt;strong&gt;HYPOTHESIS&lt;/strong&gt; of linear regression would change:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/hypothesis.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;where theta are parameters.&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-for-multiple-variables:18551688c5d64608a15d5425bef6ac07&#34;&gt;Gradient descent for multiple variables&lt;/h3&gt;

&lt;p&gt;So as the number of parameter grows, remember to simultaneously update theta_j for j = 0,&amp;hellip;,n
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/grad.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;where &lt;strong&gt;COST FUNCTION&lt;/strong&gt; is still the same:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/cost.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-in-practice-i:18551688c5d64608a15d5425bef6ac07&#34;&gt;Gradient descent in practice I&lt;/h3&gt;

&lt;h4 id=&#34;feature-scaling:18551688c5d64608a15d5425bef6ac07&#34;&gt;Feature Scaling&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The idea of Feature Scaling is to make sure features are on a similar scale, then gradient descents can converge more quickly.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/feature-scaling.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;More generally, get every feature into approximately a -1 ≤ x ≤ 1 range.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/range.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;mean-normalization:18551688c5d64608a15d5425bef6ac07&#34;&gt;Mean normalization&lt;/h4&gt;

&lt;p&gt;In addition to dividing by so that the maximum value when performing feature scaling sometimes people will also do what&amp;rsquo;s call mean normalization, which means that replace x with x - μ to make features have approximately zero mean(Do not apply to x0 = 1)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/mean-normalization.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;parameters-explanation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Parameters explanation:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;μ1 - the average value of x in the training set&lt;/li&gt;
&lt;li&gt;s1 - the range(max - min) of values of that feature&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;gradient-descent-in-practice-ii:18551688c5d64608a15d5425bef6ac07&#34;&gt;Gradient descent in practice II&lt;/h3&gt;

&lt;h4 id=&#34;so-in-gradient-descent-how-do-we-make-sure-gradient-descent-is-working-correctly:18551688c5d64608a15d5425bef6ac07&#34;&gt;So in gradient descent, how do we make sure gradient descent is working correctly?&lt;/h4&gt;

&lt;p&gt;Here is something we can do. We know that the job of gradient descent is to find the theta for you that, you know, hopefully minimizes the cost function j of theta. So we pluck the cost function j of theta as the gradient descent runs. And plot that maybe looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/decrease.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So what this plot is showing, &lt;strong&gt;is it&amp;rsquo;s showing the value of your cost function after each iteration of gradient descent, and the gradient descent is working properly, then J of theta should decrease after every iteration&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In this case, we can tell gradient descent is not working
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/not-working.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;And one useful thing that this should of plot can tell you also is that by the time you&amp;rsquo;ve gotten out to maybe between three hundred and four hundred iterations, it looks like that J of theta hasn&amp;rsquo;t gone down much more. So it looks like that J of theta have more or less converged because your cost function isn&amp;rsquo;t going down much more. &lt;strong&gt;So looking at the figure can also help you judge whether or not gradient descent has converged&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;By the way, the number of iterations that gradient descent takes to converge for a particular application can vary a lot. &lt;strong&gt;So it is hard to tell how many iteration gradient descent needs to converge, and is usually by plotting this sort of plot to try to tell if gradient descent has converged&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;It is also possible to come up with &lt;strong&gt;automatic convergence test&lt;/strong&gt;, namely to have a algorithm to try to tell you if gradient descent has converged. Say we can declare convergence if J of theta decreases by less than 10^(-3) in one iteraion. But the threshold is very difficult to decide. So maybe simply plot the figure is a proper choice.&lt;/p&gt;

&lt;h4 id=&#34;how-to-choose-learning-rate-alpha:18551688c5d64608a15d5425bef6ac07&#34;&gt;How to choose learning rate alpha?&lt;/h4&gt;

&lt;p&gt;If alpha is too small, slow convergence. If alpha too large, J of theta may not decrease on every iteraion or may not converge.&lt;/p&gt;

&lt;p&gt;So when run gradient descent, try a range of values: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1 and pick the alpha seems to be causing J of theta to decrease rapidly.&lt;/p&gt;

&lt;h3 id=&#34;features-and-polynomial-regression:18551688c5d64608a15d5425bef6ac07&#34;&gt;Features and polynomial regression&lt;/h3&gt;

&lt;p&gt;How to get different algorithm, sometimes very powerful ones by choosing appropriate features.&lt;/p&gt;

&lt;p&gt;Suppose for housing prices prediction problem, we have two features: frontage, depth. But when we apply linear regression, you don&amp;rsquo;t necessary have to use the exactly features x1 and x2 but can create new features by yourself.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/area.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So sometimes by defining new features you might actually get a better model. Closing to the idea of choosing features is this idea called polynomial regression. Let&amp;rsquo;s say your house price looks like this:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/quad-and-cubic.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;We can apply quadratic function or cubic function, but both of these function may not be ideal. When we use cubic function, x1, x2 and x3 take a very diffierent ranges of values, and it&amp;rsquo;s important to use feature scaling if using gradient descent.&lt;/p&gt;

&lt;p&gt;So we may find another reasonable choice like this:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/ideal.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;We do have a broad choice on feature choosing for models.&lt;/p&gt;

&lt;h3 id=&#34;normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Normal equation&lt;/h3&gt;

&lt;p&gt;Normal equation, which for some linear regression problems, will give us a much better way to solve for the optimal value of the parameters theta.&lt;br /&gt;
&lt;strong&gt;Normal equation is a method to solve for theta analytically.i.e. we can instead just solve for the optimal value for theta all at one go&lt;/strong&gt;. So basically one step you get to the optimal value right there.&lt;/p&gt;

&lt;h4 id=&#34;formula-of-normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Formula of Normal equation&lt;/h4&gt;

&lt;p&gt;Using this formula &lt;strong&gt;does not require any feature scaling&lt;/strong&gt;, and you will get an exact solution in one calculation: there is no “loop until convergence” like in gradient descent.&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/normal-equation.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;intuition-of-normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;Intuition of normal equation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/intuition.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h4 id=&#34;when-to-use-gradient-descent-and-when-to-use-normal-equation:18551688c5d64608a15d5425bef6ac07&#34;&gt;When to use gradient descent and when to use normal equation?&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week2/grad-and-NE.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So if n is large, use gradient descent to avoid to pay this all in q time, but if n is relatively small, then the normal equation might give you a better way to solve the parameters.&lt;/p&gt;

&lt;h5 id=&#34;what-does-the-small-and-large-means:18551688c5d64608a15d5425bef6ac07&#34;&gt;What does the small and large means?&lt;/h5&gt;

&lt;p&gt;If n is in the order of a thousand, still use  normal equation. But if n is ten thousand, inverting a ten-thousand by ten-thousand matrix starts to get kind of slow. And may then to lean in the direction of gradient descent. It is hard to give a strict number. It is usually around then thousand that start to consider switching over normal equation to gradient descent.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linear Regression with one variable</title>
      <link>http://shirleychou.github.io/blog/2016/01/25/linear-regression/</link>
      <pubDate>Mon, 25 Jan 2016 14:03:34 +0800</pubDate>
      
      <guid>http://shirleychou.github.io/blog/2016/01/25/linear-regression/</guid>
      <description>

&lt;p&gt;Let’s start by talking about a few examples of supervised learning problems. Suppose we have a dataset giving the living areas and prices of 47 houses from Portland, Oregon:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/house-prices.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;To establish notation, use &lt;strong&gt;x(i)&lt;/strong&gt;(above) to denote the &amp;ldquo;input&amp;rdquo; variables (living area in this example), also called &lt;strong&gt;input features&lt;/strong&gt;, and &lt;strong&gt;y(i)&lt;/strong&gt; to denote the “output” or &lt;strong&gt;target variable&lt;/strong&gt; that we are trying to predict(price). A pair &lt;strong&gt;(x(i), y(i))&lt;/strong&gt; is called a &lt;strong&gt;training example&lt;/strong&gt;. And use &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; denote the space of input values, &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt; the space of output values. In this example, &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; = &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt; = &lt;strong&gt;&lt;em&gt;R&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;And the goal is, given a training set, to learn a function h : &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; → &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt; so that h(x) is a &amp;ldquo;good&amp;rdquo; predictor for the corresponding value of y. This function &lt;em&gt;h&lt;/em&gt; is called a &lt;strong&gt;hypothesis&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;To perform supervised learning, we must decide how we’re going to represent functions/hypotheses h in a computer. As an initial choice, let’s say we decide to approximate y as a linear function of x:&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/hypo.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;br /&gt;
Here, the θi’s are the &lt;strong&gt;parameters&lt;/strong&gt;(also called weights) parameterizing the space of linear functions mapping from &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;em&gt;Y&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;cost-function:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Cost function&lt;/h3&gt;

&lt;p&gt;Now, given a training set, how do we pick, or learn, the parameters θ? One reasonable method seems to be to make h(x) close to y, at least for the training examples we have. To formalize this, we will define a function that measures, for each value of the θ’s, how close the h(x(i))’s are to the corresponding y(i)’s. We define the cost function:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/cost.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;parameters-explanation:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Parameters explanation:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;This is called Squared error function&lt;/li&gt;
&lt;li&gt;1/2m

&lt;ul&gt;
&lt;li&gt;1/m - means we determine the average&lt;/li&gt;
&lt;li&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; - the 2 makes the math a bit easier, and doesn&amp;rsquo;t change the constants we determine at all (i.e. half the smallest value is still the smallest value!)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Minimizing θ0/θ1 means we get the values of θ0 and θ1 which find on average the minimal deviation of x from y when we use those parameters in our hypothesis function&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;cost-function-intuition:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Cost function intuition:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;Cost function is a way to, using your training data, determine values for your θ values which make the hypothesis as accurate as possible&lt;/li&gt;
&lt;li&gt;It also called the squared error cost function&lt;/li&gt;
&lt;li&gt;This cost function is reasonable choice for most regression functions. And is probably most commonly used function&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;a-deeper-insight-into-the-cost-function:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;A deeper insight into the cost function&lt;/h3&gt;

&lt;p&gt;So we know that the cost function determines parameters. In order to visualize cost function J a little bit easier, we assume θ0 = 0 and now the goal is to minimize cost function J(θ1). If we compute a range of values plot, we get a polynomial (looks like a quadratic):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/theta_1.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The optimization objective for the learning algorithm is to find the value of θ1 which minimizes J(θ1). θ1 = 1 is the best value for θ1 here.&lt;/p&gt;

&lt;p&gt;Now we use our original complex hypothesis with two variables: J(θ0, θ1) and draw a &lt;strong&gt;3D surface plot&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/surface-plot.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;notice:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Notice&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;the height(y) indicates the value of the cost function, so the goal is to find where y is at a minimum.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And also, we can plot a &lt;strong&gt;contour plots&lt;/strong&gt; for better intuition:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/contour.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;notice-1:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Notice&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;each color is the same value of J(θ0, θ1), but obviously plot to different locations because θ1 and θ0 will vary&lt;/li&gt;
&lt;li&gt;each point (like the pink one above) represents a pair of parameter values for Ɵ0 and Ɵ1&lt;/li&gt;
&lt;li&gt;Finding Ɵ0 and Ɵ1 by eye/hand is in pain. What we really want is an efficient algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lms-algorithm:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;LMS algorithm&lt;/h2&gt;

&lt;p&gt;We want to choose θ so as to minimize J(θ). Specifically, let’s consider the &lt;strong&gt;gradient descent algorithm&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-algorithm:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Gradient descent algorithm&lt;/h3&gt;

&lt;h4 id=&#34;how-does-it-work:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;How does it work?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Start with initial guesses (0,0 (or any other value))&lt;/li&gt;
&lt;li&gt;Keeping changing θ0 and θ1 a little bit to try and reduce J(θ0, θ1). Each time you change the parameters, you select the gradient which reduces J(θ0,θ1) the most possible&lt;/li&gt;
&lt;li&gt;Repeat&lt;/li&gt;
&lt;li&gt;Do so until hopefully converge to a value of θ that minimizes J(θ)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;the-definition-of-gradient-descent-algorithm:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;The definition of gradient descent algorithm&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/grad.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;h5 id=&#34;parameters-explanation-1:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Parameters explanation:&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Alpha (learning rate)&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When you get to a local minimum, gradient of tangent/derivative is 0. So derivative term = 0 and theta remains the same.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/learning-rate.JPG?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;As we approach a local minimum, gradient descent will automatically take smaller steps. So no need to decrease alpha over time.&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/smallstep.JPG?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;derivative term&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Remember to use &lt;strong&gt;partial derivative&lt;/strong&gt; when we have multiple variables but only derive with respect to one.&lt;/li&gt;
&lt;li&gt;Despite the value of x (positive or negative), J(θ) will always reduce.
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/derivative.JPG?raw=true&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;notice-2:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Notice!&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;HAVE TO SIMULTANEOUSLY&lt;/strong&gt; update j = 0 and j = 1. If you implement the non-­simultaneous update it&amp;rsquo;s not gradient descent, and will behave weirdly.&lt;br /&gt;
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/theta_update.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;An interesting property: &lt;strong&gt;Where you start&lt;/strong&gt; can &lt;strong&gt;determine&lt;/strong&gt; which minimum you may end up
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/local-minimum.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;batch-gradient-descent:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;&amp;ldquo;Batch&amp;rdquo; Gradient Descent&lt;/h4&gt;

&lt;p&gt;“Batch”: Each step of gradient descent uses all the training examples.&lt;/p&gt;

&lt;h3 id=&#34;linear-regression-with-gradient-descent:2b2db294fcac5ab3df0f477bdb61214d&#34;&gt;Linear regression with gradient descent&lt;/h3&gt;

&lt;p&gt;Apply gradient descent to minimize the squared error cost function J(θ0, θ1). When we derive this expression in terms of j = 0 and j = 1 we get the following:
&lt;img src=&#34;https://github.com/shirleyChou/blog/blob/master/static/content/post/images/andrew-ng-ml/week1/derive-cost.JPG?raw=true&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Since the &lt;strong&gt;linear regression&lt;/strong&gt; cost function is always a convex function(Bowl shaped), So gradient descent will always converge to &lt;strong&gt;global optima&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>